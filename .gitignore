import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import shap
import joblib
import logging
from flask import Flask, request, jsonify
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, classification_report
from imblearn.over_sampling import SMOTE
from sklearn.pipeline import Pipeline

logging.basicConfig(filename='intrusion_detection.log', level=logging.INFO)

train_data = pd.read_csv(r'C:\Users\shame\Desktop\ML\project codes\KDDTrain+.txt', header=None)
test_data = pd.read_csv(r'C:\Users\shame\Desktop\ML\project codes\KDDTest+.txt', header=None)

train_data = train_data.iloc[:, :42]
test_data = test_data.iloc[:, :42]

sample_size = 10000
train_data = train_data.sample(n=sample_size, random_state=42)
test_data = test_data.sample(n=sample_size, random_state=42)

if train_data.shape[1] != 42 or test_data.shape[1] != 42:
    raise ValueError("Number of columns in the dataset does not match the expected number of columns.")

columns = ["duration", "protocol_type", "service", "flag", "src_bytes", "dst_bytes", "land", "wrong_fragment", "urgent",
           "hot", "num_failed_logins", "logged_in", "num_compromised", "root_shell", "su_attempted", "num_root",
           "num_file_creations", "num_shells", "num_access_files", "num_outbound_cmds", "is_host_login", "is_guest_login",
           "count", "srv_count", "serror_rate", "srv_serror_rate", "rerror_rate", "srv_rerror_rate", "same_srv_rate",
           "diff_srv_rate", "srv_diff_host_rate", "dst_host_count", "dst_host_srv_count", "dst_host_same_srv_rate",
           "dst_host_diff_srv_rate", "dst_host_same_src_port_rate", "dst_host_srv_diff_host_rate", "dst_host_serror_rate",
           "dst_host_srv_serror_rate", "dst_host_rerror_rate", "dst_host_srv_rerror_rate", "label"]

train_data.columns = columns
test_data.columns = columns

data = pd.concat([train_data, test_data])

categorical_columns = ["protocol_type", "service", "flag"]
label_encoder = LabelEncoder()
for column in categorical_columns:
    data[column] = label_encoder.fit_transform(data[column])

train_data = data.iloc[:len(train_data), :]
test_data = data.iloc[len(train_data):, :]

X_train = train_data.drop('label', axis=1)
y_train = train_data['label']
X_test = test_data.drop('label', axis=1)
y_test = test_data['label']

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf, average='weighted', zero_division=1)
recall_rf = recall_score(y_test, y_pred_rf, average='weighted', zero_division=1)
f1_rf = f1_score(y_test, y_pred_rf, average='weighted')

print('RandomForest - Accuracy:', accuracy_rf)
print('RandomForest - Precision:', precision_rf)
print('RandomForest - Recall:', recall_rf)
print('RandomForest - F1 Score:', f1_rf)

metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
values = [accuracy_rf, precision_rf, recall_rf, f1_rf]

plt.figure(figsize=(10, 6))
plt.bar(metrics, values, color=['blue', 'green', 'orange', 'red'])
plt.title('RandomForest Model Evaluation Metrics')
plt.xlabel('Metrics')
plt.ylabel('Score')
plt.ylim(0, 1)
plt.savefig('visualization_random_forest_metrics.png')
plt.show()

plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred_rf)
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix - RandomForest')
plt.colorbar()
tick_marks = np.arange(len(np.unique(y_test)))
plt.xticks(tick_marks, np.unique(y_test), rotation=45)
plt.yticks(tick_marks, np.unique(y_test))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.savefig('confusion_matrix_random_forest.png')
plt.show()

plt.figure(figsize=(8, 6))
fpr, tpr, _ = roc_curve(y_test, rf_model.predict_proba(X_test)[:, 1])
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - RandomForest')
plt.legend(loc="lower right")
plt.savefig('roc_curve_random_forest.png')
plt.show()

explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test, feature_names=X_test.columns)

joblib.dump(rf_model, 'random_forest_id_model.pkl')

app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.get_json()
        input_data = pd.DataFrame(data, index=[0])
        prediction = rf_model.predict(input_data)
        response = {'prediction': prediction[0]}
        return jsonify(response)
    except Exception as e:
        logging.error(f"Error occurred: {e}")
        return jsonify({'error': str(e)}), 400

if __name__ == '__main__':
    app.run(debug=True)
